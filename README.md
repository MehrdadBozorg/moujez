<a href="http://moujez.ir" style="margin: 0 auto;text-align: center;" target="_blank">
<img src="http://moujez.ir/static/images/logo.png" />
</a>

** نسخه آزمایشی: **‌ پیاده سازی اولیه را از [این‌جا](http://moujez.ir/) مشاهده نمایید. لطفا در صورت مشاهده‌ی باگ، [گزارش دهید](https://github.com/kharazi/moujez/issues). 
برای استفاده یک لینک یک خبر یا مقاله را در ورودی وارد کنید و دکمه مشاهده‌ی خلاصه را بزنید در صورتی که برای آن خبر کار نکرد لطفا لینک را گزارش دهید. ضمن عذرخواهی، ممکن است در بعضی ساعات به خاطر ایراد در vps یا تغییر کد در بعضی از ساعات کار نکند.


# چکیده
در این پروژه، ابتدا به بیان و پیاده‌سازی چند روش خلاصه‌سازی متن خواهیم پرداخت و تکنیک‌های خاصی را که منحصرا به خلاصه‌سازی خبر مربوط می‌شوند را توضیح می دهیم. سپس کارگزارِ[^1] خلاصه‌سازیِ خبرِ [موجز](https://bitbucket.org/vahidkharazi/moujez)، که از ترکیب چند روش خلاصه‌سازی آماری و یادگیریِ ماشین استفاده می‌ کند را معرفی می کنیم. موجز، از تکنیک‌های مربوط به پردازش زبان طبیعی و قواعد مربوط به زبان فارسی برای بهبود نتایج خود استفاده می کند. پس از پیاده سازی این سیستم با زبان برنامه نویسی پایتون‌، نتایج را با یک مجموعه‌ی خبر که توسط انسان خلاصه شده‌است مقایسه می‌‌‌کنیم و این سیستم را با روش‌‌‌های ارزیابی ذاتی و بیرونی سیستم‌‌‌های اتوماتیک خلاصه سازی‌، می‌‌‌سنجیم‌. نشان خواهیم داد که در بدترین حالت،‌معیار دقت[^2] این سیستم حدود ۷۶ درصد و معیار فراخوانی[^3] حدود ۶۱ درصد است.

# ۱. مقدمه
در سال‌‌‌های اخیر نرخِ رشدِ اطلاعات، بسیار فزاینده است‌. با توجه به این افزایش حجم مستندات متنی‌، برای پاسخگویی به نیاز‌‌‌های اطلاعاتی کاربران‌، دیگر تکنیک‌‌‌های بازیابی اطلاعات به تنهایی کارا نیستند‌. از این رو خلاصه‌سازی متن‌‌‌ها به منظور فهم کلیه اطلاعات بااهمیت متن از جایگاه ویژه‌ای برخوردار است‌. این‌ کار منجر به استفاده از منابع بیشتر و با سرعت بالا‌‌تر و در نتیجه حاصل شدنِ اطلاعاتِ غنی‌‌‌تر می‌‌‌شود‌. امروزه کارگزار‌‌‌های خلاصه‌ساز متن در خلاصه‌سازی اطلاعاتِ پزشکیِ بیماران[1]، سرویس‌‌‌های صوتی برای ناشنوایان، موتور‌‌های جستجو، خلاصه‌سازی نامه‌‌‌‌های الکترونیکی[2]، اخبار[29] و غیره کاربرد دارند‌.

## ۱.۱. انواع خلاصه‌سازی متن
در منابع[4,3]، دسته‌بندی‌های مختلفی برای کارگزارهای خلاصه‌سازی معرفی شده است که وجوهِ مشترک بسیاری دارند:

* **نوع خلاصه: **به طور کلی خلاصه‌سازی به دو نوع مستخرج[^4] و چکیده[^5] تقسیم بندی می‌شود. در خلاصه‌های مستخرخ، جملاتی از متنِ اصلی، به عنوان جملاتِ مهم از سند در خلاصه انتخاب می‌شوند اما در خلاصه‌های چکیده، خروجی می‌تواند شاملِ جملات جدیدی باشد که دربرگیرندهِ اطلاعات مهم متن است. اکثر سیستم‌های خلاصه‌ساز، خلاصه‌های مستخرج تولید می‌کنند[5].

* ** تعداد اسناد: **کارگزار خلاصه‌ساز می‌تواند، یک سندِ مجزا را خلاصه کند یا چندین سند را که یک رویداد را گزارش می‌دهند خلاصه کند.


* **پارامتر:** خلاصه‌ی یک متنِ یکسان، می‌تواند برای هر کاربر، با توجه به ویژگی‌های شخصی وی، متفاوت باشد.[6] ویژگی‌های کاربر می‌تواند به صورت هوشمند یا با پرسش از وی استخراج شود.

دسته‌بندی‌های دیگری نیز برای خلاصه‌سازی ارایه شده‌ است که به دلیل ارتباط کمتر با این مطالعه‌ی موردی، ذکر نشده است.

## ۱.۲. چالش‌های پیش‌رو
* **حفظ پیوستگی:‌** خلاصه‌سازی با رویکرد مستخرج، باعث حذف برخی از جملات می شود. ممکن است جملات متن خلاصه، دچار گسستگی و عدم ارتباط موضوعی با یکدیگر باشند.
* **ضمایر سرگردان:** ممکن است مرجع برخی ضمیرها مانند «وی» و «آن» در جملاتی باشد که حذف شده‌اند و خود جملاتِ شامل این ضمیرها، در متن خلاصه شده آمده باشد. این موضوع باعث ابهام و کاهش خوانایی متن می‌شود.
* **استاندارد متون:** عدم رعایت استانداردی یکسان در متون خبری، به ویژه محتوای خبری که توسط خبرگزاری‌های فارسی تولید می‌شود باعث ایجاد مشکل خواهد شد. به عنوان مثال، قرارندادن علایم نگارشی در یک متن باعث می شود که تحلیل‌گرهای زبان‌های طبیعی، دچار خطا شوند. خطا در تحلیل جایگاه کلمات، باعث خطا در تکنیک‌هایی که از ویژگی‌های زبان استفاده می‌کنند خواهد شد.
* **حجم خلاصه:** یافتن میزان مطلوب کاهش حجم یک متن به صورت خودکار، توسط سیستم خلاصه‌ساز یکی از چالش های اصلی در زمینه پیاده سازی و ارزیابی سیستم های خلاصه سازی است[7].
* **ارزیابی کیفیت خلاصه: **ارزیابی خروجی سیستم خلاصه‌ساز گاهی اوقات یک موضوع کیفی است[8]. در بعضی از موارد حتی مشاهده می‌شود که یک خلاصه توسط دوفرد مختلف متفاوت ارزیابی می‌شود. کمی نبودن برخی از معیارهای ارزیابی، یک چالش اساسی محسوب می‌شود.
* **پردازش زبان فارسی: ** در توسعه این سیستم علاوه بر چالش های معمول های پردازش زبان طبیعی، مشکلات خاصی نیز وجود دارد که مرتبط با قواعد زبان فارسی هستند. مشکل دیگر در پردازش زبان فارسی کم بودن منابع زبانی، مثل پیکره‌های متنی مناسب برای این زبان است[9]. 
* **واکشی خبر: ** یافتن متن اصلی خبر و عنوان آن از صفحه وب، یکی از مراحل کارِ خلاصه‌ساز است. این مرحله به دلیل گستردگی و تفاوت سایت‌های خبرگزاری‌ها یک چالش محسوب می‌شود.

# ۲. مراحل و روش‌های موجود
به طور کلی عمل خلاصه‌سازی در سه مرحله‌ی پیش‌پردازش‌، پردازش و تولید خلاصه انجام می‌‌‌شود‌. در خلاصه‌سازی اخبار‌، باید مرحله واکشی خبر را نیز به ابتدای این مراحل اضافه نماییم‌:
## ۲.۱. واکشی خبر
ما‌، واکشی را‌، استخراجِ متنِ اصلیِ خبر، عنوان آن و مهم‌ترین تصویر موجود مرتبط، از یک صفحه وب تعریف می‌‌‌کنیم‌. واکشی تصویر مرتبط به خبر، از آن جهت اهمیت دارد که گاهی، تمام خبر در یک تصویر خلاصه می‌شود یا در برخی موارد، خبر توضیحی از تصویر است و بدون وجود آن، بی‌معنی.

واکشی متن و عنوان اصلی یک خبر یا مقاله از صفحه وب‌، به دلیل یکسان نبودن ساختار صفحات سایت‌‌‌های مختلف نیاز به به‌کارگیری تکنیک‌‌‌های مختلفی دارد. برای این‌کار دو مرحله‌ی زیر را، پیشنهاد می‌کنیم:

* ** واکشی بر پایه‌ی ساختار صفحات وب:**  
طبق بررسی ها، اکثر سایت‌های خبرگزاری‌های فارسی، عموما از دو نرم‌افزار اتوماسیون خبرگزاری [ایران سامانه](http://iransamaneh.com/) و [استودیو خبر](http://www.news-studio.com/) استفاده می‌کنند. بنابراین ساختار صفحات وب این سایت‌ها عموما مشابه است. برای این سایت‌هامی‌توان، با استفاده از شناسایی موقعیت تگ‌های html به راحتی و به طور دقیق، عنوان و متن اصلی خبر را استخراج کرد. واکشی تصویر هم برای این سرویس‌ها به سادگی با استفاده از تگ‌های تصویر انجام می‌گیرد.

* ** واکشی بر پایه‌ی روش‌های هوشمند: ** 
اگر ساختار html صفحه ای که لینک آن را داریم(مانند بالا) مشخص نبود باید بتوانیم متن اصلی و عنوان خبر را از آن استخراج کنیم. برای واکشی عنوان و متن اصلی مقاله، روش زیر به ذهن می‌رسد:

برای پیدا کردن متن اصلی خبر، ابتدا تمامی تگ‌هایی مانندِ تگ` <p> `را حذف می کنیم. سپس از بین بخش‌های مختلف متنی، بزرگترین قسمت را به عنوان متن اصلی در نظر گرفته و واکشی می کنیم. برای یافتن عنوان خبر، می‌توان از تگ` <title> `استفاده کرد. چنانچه عنوان خبر در این تگ نبود می‌توان به دنبال تمامی تگ‌هایی گشت که یک متن را بزرگنمایی می کنند.(مثل` <h1> `یا` <b>`)
در این صورت ممکن است چندین گزینه برای انتخاب عنوان وجود داشته باشد. اگر چنین اتفاقی افتاد، ابتدا با یکی از روش های‌های یافتن کلمات کلیدی در متن.(مانند روش tf-idf)، کلمات کلیدی متن را استخراج می‌کنیم[10]. سپس گزینه‌ای را انتخاب می‌کنیم که کلمات کلیدی بیشتری در آن وجود داشته باشد.

برای واکشی تصویر مرتبط به خبر،‌ به دنبال تگ` ‌<img>‌`ای می‌گردیم که پدر یا همزاد آن در سند html، متن اصلی خبر باشد(نزدیک‌ترین تصویر به متن اصلی در صورت وجود).


البته کتابخانه‌های قدرتمندی مثل کتابخانه‌ی [readability](https://github.com/buriy/python-readability) برای استخراج متن اصلی و عنوان یک مقاله از یک صفحه‌ی وب وجود دارند. در پیاده‌سازی موجز از تلفیقی از این کتابخانه و روش‌های توضیح داده شده استفاده شده است.
 
## ۲.۲ پیش‌پردازش

به دلیل عدم رعایت استانداردهای نگارشی زبان فارسی توسط منابع، پیش از انجام هر عملی به روی متنی که از صفحه وب واکشی شده است، باید پیش‌پردازش را انجام دهیم تا به متونی استاندارد برسیم. کارهای مرتبط پیشین[11, 5]، کارهای زیادی را برای پیش پردازش زبان فارسی پیشنهاد داده‌اند که البته برخی از آن‌ها،‌نادرست، فاقد دلیل منطقی و یا مغایر با شیوه‌ی درست نگارش زبان فارسی[12] به نظر می‌رسند و باعث پردازش اضافی بر روی متن می‌شوند. در زیر اعمالی را که برای پیش‌پردازش زبان فارسی، منطقی به نظر می رسد را ذکر می کنیم:

* تبدیل نویسه‌‌ «ی» و «ک» عربی به نوع فارسی آن‌ها
* تبدیل نویسه های «ؤ» به «و»، «ئ» به «ی» و «أ» به «ا»
* تبدیل حمزه‌ی آخر کلمات به «ی» با رعایت نیم فاصله مناسب
* اصلاح فاصله‌گذاری نادرست پرانتزها
* تبدیل اعداد عربی و انگلیسی به معادل فارسی آن‌ها
* رعایت نیم‌فاصله در پسوندهایی مانند «ها»، «تر»، «تری» و «ترین»
* رعایت نیم‌فاصله در ضمایر ملکی نظیر «ام»، «ای»، «ات» و «اش»
* رعایت نیم‌فاصله در پیشوندهایی همچون «نمی» و «می» در ابتدای فعل‌ها
* حذف بیش از یک علامت سوال یا علامت تعجب
* اصلاح کشیدگی کلماتی مانند «وحیـــــــد»
* حذف فاصله پس از پیشوند «بر» در واژه‌هایی مانند «بر می‌گردد»
* چسباندن علایم نگارشی مانند نقطه و علامت سوال به انتهای جمله

## ۲.۳. پردازش
در این مرحله، اعمالی جهت بهبود نتایج کارِ خلاصه‌ساز بر روی متن اصلی انجام می‌شود که به طور خلاصه، تعدادی از آن‌ها را در زیر مطرح می‌کنیم. تعدادی از این مراحل، برای همه‌ی خلاصه‌سازها مناسب است و تعدادی از آن‌ها منحصرا نتایج خلاصه‌ساز خبر را بهبود می‌دهد:
###  ۲.۳.۱. حذف کلمات ایست
یک پیکره از افعال، کلمات پرتکرار، ضمایر، قیدها، حروف ربط، حروف اضافه و حروف تعریف را به عنوان پیکره‌ی کلمات ایست فارسی در نظر گرفتیم و آن‌ها را از متن اصلی حذف می‌کنیم زیرا این کلمات ارزش پایینی در درک مفهوم از جمله دارند. این لیست  حتما باید متناسب با سیستم خلاصه‌ساز خبری تنظیم شود چون بعضی از واژه‌ها مانند  «چون» و «زیرا» و ... در بیشتر لیست‌های کلمات ایست فارسی هستند ولی در خبر، واژه‌های مهمی محسوب می‌شوند. حذف کلمات ایست به بهبود نتایج کمک بسیار زیادی می‌کند.
### ۲.۳.۲. دادن امتیاز بیش‌تر به کلمات عنوان اصلی خبر
عنوان خبر، شامل کلمات اصلی خبر است و می‌توان در متن نیز امتیاز بیش‌تری برای جملاتی که حاوی این کلمات هستند در نظر گرفت. فقط باید دقت داشت که کلمات ایست حتما بایستی از عنوان خبر حذف شوند. 
### ۲.۳.۳. موجودیت‌های نامدار
موجودیت‌های نامدار در زبان، به مجموعه‌ای از اسامی مانند نام افراد، سازمان‌ها، مکان‌ها و ... است. تشخیص موجودیت‌های نامدار متن از دوجهت در خلاصه‌سازی متن اهمیت دارد:
**۱. امتیازدهی به جملات حاوی موجودیت‌های نامدار**
در خبرها، معمولا جملاتی که موجودیت نامدار دارند از اهمیت بالایی برخوردارند لذا بایستی به آن‌ها امتیاز زیادی داد.
**۲. رفع ابهام جملات با جایگزینی ضمایر با اسامی **
همانطور که گفته شد، یک چالش اساسی در خلاصه‌سازی متن ضمایر مبهم هستند. معمولا در ۸۰ درصد موارد، مرجع ضمیر در جمله قبلی می‌باشد[30].در حالت ایده‌آل بایستی ضمیر را با مرجع آن جایگزین کرد.

آزمایش پردازش زبان طبیعی دانشگاه استنفورد، [یک ابزار بسیار قدرتمند](http://nlp.stanford.edu/software/CRF-NER.shtml) برای تشخیص موجودیت‌های نامدار در متن ارایه داده است. یک پیکره‌ی متنی شامل موجودیت‌های نام‌دار فارسی را هم مهندس مجید عسگری ساخته‌اند و لطف کردند و برای بنده ارسال کردند و فعلا از آن پیکره و کد برای تشخیص موجودیت‌های نامدار استفاده کردم. ( ** توضیح:** به دلیل محرمانگی پیکره کدهای مربوط به این پیکره و خود پیکره در یک branch دیگر هستند و آن‌ها را  روی سورس قرار نداده‌ام)
### ۲.۳.۴. امتیاز مثبت به جملات حاوی اعداد، علامت درصد(٪) و کلمات بیگانه
وجود علامت درصد و اعداد در متن خبرها، معمولا نشان از آماردهی دارد و بهتر است جملات حاوی اعداد و علامت درصد مهم‌تر تلقی شوند و در خلاصه بیایند.
همچنین معمولا کلمات انگلیسی در متن فارسی، کلماتی هستند که جایگزین فارسی ندارند یا به دلیل اهمیتشان، به همراه ترجمه فارسی آمده‌اند و یا اسامی خاص هستند که ترجمه نشده‌اند، لذا بهتر است که برای جملات حاوی این کلمات نیز، امتیاز بیش‌تری در نظر گرفت.
### ۲.۳.۵. امتیاز مثبت به جملات حاوی نقل قول
جملات درون علامت نقل قول، معمولا جملات مهم‌تری در خبر هستند. البته باید دقت داشت که آوردن این جملات در متن خلاصه، گاهی باعث گسستگی بیش‌تر متن می‌شود.
### ۲.۳.۶. در نظر گرفتن امتیاز کلمات یا عبارات اشاره
کلمات اشاره کلماتی عمومی‌ هستند که حضورشان در جمله می‌تواند نشانه‌ی اهمیت یا عدم اهمیت آن جمله باشد. به عنوان مثال برای جملاتی که حاوی کلماتی مانند «نتیجه» و «بنابراین»  و «مقاله»  و «موضوع» هستند می‌توان امتیاز بیش‌تری در نظر گرفت چون نشان از جمع‌بندی دارند. همچنین می‌توان از جملاتی که حاوی کلماتی مانند  «مثلا» و  «مانند» و «همچون» هستند امتیاز کسر کرد.
### ۲.۳.۷. امتیازدهی به طول جملات
طول جملات یک معیار مهم هستند که در مرحله پردازش باید در امتیاز دهی به جملات در نظر گرفته شوند. جملاتی که طولشان خیلی‌کم یا خیلی‌زیاد است جمله‌‌های خوبی برای آمدن در متن خلاصه نیستند. 
### ۲.۳.۸. امتیاز مثبت به برچسب‌های خبر
با توجه به یکسان بودن سیستم اکثر وبسایت‌های خبری فارسی، همانطور که در بخش واکشی توضیح داده شد می‌توان برچسب‌هایی که خبرنگاران برای یک خبر وارد کرده‌اند را نیز واکشی کرد. چون این کلمات توسط انسان(و نه ماشین) استخراج شده‌اند می‌توان امتیاز مثبت زیادی برای جملات حاوی این واژه‌ها در نظر گرفت.
## ۲.۴. تولید خلاصه
تاکنون روش‌های زیادی برای تولید خلاصه از یک متن پیشنهاد شده است. در این بخش تعدادی از آن‌ها را بررسی می‌کنیم:
### ۲.۴.۱ روش TF-ISF

این روش برگرفته از معیار فرکانس کلمه - معکوس فرکانس سند در بازیابی اطلاعات است. فرکانس یک کلمه، تعداد تکرار آن در متن است. فرکانس جمله، تعداد جملات سند است که حاوی آن کلمه هستند. این مشخصه بعد از حذف تمامی کلمات ایست[^6]، برای تمام کلمات هر جمله محاسبه می شود. وزن هر جمله از مجوع وزن کلمات آن جمله تقسیم بر تعداد کلمات آن بدست می آید و در نهایت، بسته به حجم دلخواه خلاصه جملات با بیشترین وزن انتخاب می شوند. فرمول این روش به صورت زیر است:

$$ tf_{i,j} =  \frac{ freq_ {i,j} }{ max_ {l}  freq_ {l,j} } (1)$$ 

$$ isf_ {i}  = \log \frac {N}{n_ {i}} (2)$$

در این رابطه $is_ {i}$  تعداد تکرار کلمه و $ isf_ {i} $ بیانگر عکس تعداد تکرار جمه از کلمه i ام است.  در رابطه (2)، N تعداد کل جملات و $ n_ {i} $ تعداد جملاتی است که در آن کلمه i ام وجود دارد.

سپس وزن هر کلمه را از فرمول زیر محاسبه می کنیم.

$$ w_ {i,j} = tf_{i,j} \times  isf_ {i}$$


در نهایت وزن جملات را از تقسیم مجموع وزن کلمات آن جمله بر تعداد کلمات آن بدست می آوریم.


### ۲.۴.۲ روش مبتنی بر گراف
در این روش، سند به شکل یک گراف غیر جهت‌دار که جملات، گره‌های تشکیل دهنده آن هستند ارایه می‌شود. نظریه گراف می‌تواند برای تجسم شباهت درون‌سندی و بین‌سندی به کار گرفته شود. در واقع ما در این روش به هر جمله یک گره، اختصاص می‌دهیم و اگر یک جمله با جملات دیگر ارتباط داشته باشد، بین آن دو گره یال رسم می‌شود. معیار ارتباط بین جملات، داشتن کلمات کلیدی بیشتر، نزدیک بودن به عنوان متن و ... می‌تواند باشد. در نهایت گره‌هایی که درجه بیشتری دارند به عنوان خروجی انتخاب می‌شوند. برای به دست آوردن شباهت بین جملات از فرمول کسینوسی زیر استفاده می‌کنیم:
$$idfModifiedCosine(x, y) =  \frac{ \sum_{w \in x, y } { tf_{w,x} tf_{w,y}   (idf_{w})^{2}   } }   {  \sqrt{\sum_{x_{i} \in x }( tf_{x_{i} ,x} idf_{x_{i}} )^{2} } {  \sqrt{\sum_{y_{i} \in y }( tf_{y_{i} ,y} idf_{y_{i}} )^{2} } }} $$
که در این فرمول x و y دو جمله از سند هستند $tf_{w,s}$ تعداد رخداد کلمه‌ی w در جمله s است.
شباهت بین هر دوجمله را در سند‌ با استفاده از فرمول بالا به دست می‌آوریم و در یک ماتریس ذخیره می‌کنیم. توجه کنید که وزن اعداد این ماتریس، مقادیر بین صفر و یک هستند و مقدار بیشترین شباهت بین زمانی است که دو جمله دقیقا یکسان باشند و مقدار آن برابر یک است) سپس به کمک این ماتریس، گراف شباهت جملات را رسم می‌کنیم.
به عنوان مثال به گراف زیر توجه کنید:

![گراف مشابهت جمله‌ها](http://www.kargaheweb.com/sgraph.png)

<p style="margin: 0 auto; margin-top: -45px; margin-bottom: 15px; text-align: center">
شکل ۲-۱ گراف شباهت یک سند با یازده جمله
</p>

همانطور که مشخص است یال‌های پررنگ‌تر نشان‌دهنده‌ی شباهت بیشتر می‌باشد. حال برای به دست آوردن متن‌ خلاصه، گره‌هایی که  مجموع وزن اتصالات آن‌ها بیشتر‌ است را به عنوان خروجی در نظر می‌گیریم.



### ۲.۴.۳ روش مبتنی بر زنجیره لغوی
زنجیره‌های لغوی، کلماتی هستند که از نظر معنایی با یکدیگر در ارتباط‌ هستند. به عنوان نمونه، واژگانی نظیر کوشش، سعی و تلاش در یک زنجیره قرار می‌گیرند. روش‌های خلاصه‌سازی مبتنی بر زنجیره لغوی، در سه مرحله عمل می کنند[15]:

۱. تولید زنجیره‌های لغوی

۲. امتیاز دادن به زنجیره‌ها

۳. یافتن بهترین زنجیره برای ارزش‌دهی و استخراج جملات کلیدی

ارتباط بین‌ واژه‌های یک زنجیره لغوی می‌تواند هم‌معنی‌بودن، مخالف‌بودن، اشتقاق و شمول باشد. روش‌های زنجیره‌ی لغوی معمولا با [پیکره‌ی WordNet](http://en.wikipedia.org/wiki/WordNet) کار می‌کنند.
دو الگوریتم مختلف برای ایجاد زنجیره‌ها وجود دارد[15]: رویه غیر مبهم حریصانه و رویه غیر حریصانه. در رویه غیر مبهم حریصانه، زنجیره یک کلمه فقط به کمک کلمات قبل از آن در متن، مشخص می‌شود به این صورت که بر اساس روابط تعیین شده، اگر زنجیره مرتبط با کلمه، در زنجیره‌های از قبل موجود یافت شود آن را در همان زنجیره درج می‌کنند و در غیر این صورت برای آن یک زنجیره جدید می‌سازند. در مقابل، الگوریتم غیر حریصانه، تا هنگامی که تمامی کلمات در متن پردازش شود منتظر می‌ماند، سپس با توجه به تمام لغات متن، زنجیره هر کدام را یافته و ایجاد می‌کند.
نبود یک پیکره‌ی جامع مانند WordNetدر زبان فارسی، یک چالش‌ اساسی است و پیاده‌سازی این روش ساده و کارآمد را برای زبان فارسی غیر ممکن کرده است.
(**توضیح:** نحوه کار با WordNet در کتابخانه‌ی nltk، [این‌جا](http://www.nltk.org/howto/wordnet.html) توضیح داده شده است.)

### ۲.۴.۴روش مبتنی بر یادگیری ماشین[^21]

این روش نیاز به وجود یک مجموعه سند خبری و خلاصه آن‌ها دارد. اگر ما چنین مجموعه‌ای از داده‌ها را داشته باشیم می‌توانیم به کمک راه حل‌هایی که برای طبقه‌بندی مطرح شده‌است، مساله خلاصه‌سازی را حل می‌کنیم. در واقع در این روش ما مساله‌ی خلاصه‌سازی را به عنوان یک مساله‌ی رده‌بندی مدل می‌کنیم. در حین یادگیری، داده‌ها به یک الگوریتم رده‌بندی، داده می‌شوند. جملات به چند گروه جملات خلاصه و جملات غیر خلاصه با ویژگی‌هایی که دارند تقسیم بندی می‌شوند. برای یادگیری‌ می‌توان از روش‌هایی مانند Naive Bayes استفاده کرد[14, 23].
نکته‌ای که یادگیری ماشین‌، اهمیت دارد انتخاب و استخراج ویژگی‌هاست که با استفاده از این ویژگی‌ها بتوان دسته‌بندی جملات و گزینش آن‌ها را انجام داد. معمولا از الگوریتم ژنتیک برای استخراج ویژگی‌ها استفاده می‌شود[24]. برای نمونه ویژگی‌هایی مانند طول جمله، موقعیت جمله(چندمین جمله‌ی متن)، شباهت به عنوان، شباهت به کلمات کلیدی، شباهت به جملات دیگر و شباهت به جمله کلیدی متن(با اهمیت‌ترین جمله متن) برای استفاده در سیستم‌های خلاصه‌سازی که از روش‌های مبتنی بر یادگیری ماشین استفاده می‌کنند، مطرح می‌شود. از دیگر ویژگی‌های مطرح می‌توان به داشتن اسامی مشهور، تکرار چندین باره‌ی یک عبارت خاص و تکرار کلمات غیر ضروری نام برد.
برای راحتی کار در الگوریتم Naive Bayes فرض می‌کنیم که ویژگی‌های نام‌برده شده از هم دیگر مستقل هستند[14].


# ۳. روش پیشنهادی
## ۳.۱ تولید خلاصه
برای تولید خلاصه‌ی متن، پیشنهاد می‌شود که علاوه ضمن درنظر گرفتن تمامی نکات پیش‌پردازش و پردازش، چندین روش تولید خلاصه به صورت همزمان،‌ بر روی یک متن اعمال شود و نتایج حاصل با هم مقایسه و ادغام شوند. در نهایت جملاتی در متن خروجی نمایش داده شوند که در همه(یا اکثر)  روش‌ها، خروجی خلاصه بوده‌اند. بهتر است. 
بهتر است روش‌هایی که برای تولید خلاصه به صورت همزمان انتخاب می‌شوند از نظر ساختاری، تفاوت عمده داشته باشند. به عنوان مثال بهتر است از روش  TF-ISF که از تعداد تکرار کلمات استفاده می‌کند در کنار روش مبتنی بر فراکتال استفاده کرد.

## ۳.۲ حجم خلاصه
همانطور که گفته شد، یافتن میزان کاهش حجم در فرآیند خلاصه‌سازی یک چالش اساسی است. درصد کاهش حجم، برای کاربردهای مختلف متفاوت است. به عنوان مثال حجم یک سند پزشکی، شامل اطلاعات یک بیمار، می‌تواند بسیار کاهش بیابد و فقط در حدی اطلاعات در خلاصه بیاوریم که پزشک بتواند موارد مهم را از آن دریابد. درصد کاهش حجم، باید با توجه به نظر خبرگان هر حوزه و کاربران سیستم تعیین شود. این درصد، در کارگزارهای خلاصه‌ساز معمولا یک مقدار ثابت است ولی  بسته به شرایط می‌تواند متغییر نیز باشد یا توسط کاربر(با پرسش مستقیم) تعیین شود. چون ما در این پروژه، به طور خاص فقط خلاصه‌سازی خبر را مورد بررسی قرار دادیم. طبق یک آزمایش روانشناختی که شرح آن خارج از حوصله‌ی این گزارش است، میزان حجم مطلوب خلاصه از نظر تعدادی کاربر را سنجیدیم و  نتایج زیر بدست آمد:


<p style="margin: 0 auto; text-align: center">
جدول ۳-۱ میزان حجم مطلوب خلاصه از نظر تعدادی کاربر
 </p>

| تعداد خط‌های خبر خلاصه‌نشده|  تعداد خط‌های مطلوب از نظر کاربر برای خواندن‌ خلاصه |
|:-------------------:|:------------------------------------:|
|  ۶|‌ ۵|
| ۸ |  ۷| 
|۱۰| ۶| 
| ۱۵| ۹| 
| ... | ...| 
| ۶۰| ۱۷|
| ... | ...|
| ۹۳ | ۱۸|

لازم به ذکر است که جدول به شکل کامل آورده نشده است.  سعی شد داده ها را به کمک نرم افزار [GeoGebra](http://www.geogebra.org/cms/en/) تحلیل کرده و تابع آن را تخمین بزنیم. در نهایت دو تابع زیر(با دقت‌های مختلف) برای چنین داده‌هایی تخمین زده شد:

$$y=\frac{\left(\frac{\ln(x)}{\ln(2.42)}\right)^2}{x^{0.11}} + 1.5=\frac{\log^2_{2.42}(x)}{x^{\frac{11}{100}}}+\frac{3}{2} (3)$$

و 

$$y=\ln^2(x)+1 (4)$$

در فرمول های بالا x بیانگر تعداد خط‌های خبر اصلی و ‌y نمایانگر تعداد خط‌های خلاصه است. با توجه به سادگی فرمول (3) و نیاز محاسباتی کمتر، در پیاده‌سازی اولیه از آن استفاده کردم. به نظر می‌رسد که در صورتی که بتوان آزمایش را با جامعه‌ی آماری بالاتری انجام داد، استفاده از فرمول‌‌هایی با دقت فرمول (4) بهینه است. البته در آینده شاید بتوان با توجه دسته‌های مختلف کابران، از فرمول‌های مختلف برای هر فرد استفاده کرد(به این صورت که برای هر فرد، ثوابت فرمول با تکنیک‌های شخصی سازی تعیین شوند).


روش ارایه شده فقط به نظر کاربر توجه می‌کند و فاکتور‌های بسیار دیگری، نظیر پیوستگی مطلب خلاصه شده، را در نظر نمی‌گیرد ولی در میان روش‌های دیگری نظیر خلاصه کردن درصدی ثابت یا متغییر از دقت و فراخوانی بیشتری برخوردار است.
# ۴. ارزیابی
ارزیابی کارگزار خلاصه‌ساز متن، یک فرایند پیچیده است. زمانی که ما از ارزیابی یک سیستم خلاصه ساز، صحبت می‌کنیم باید حداقل دو ویژگی را اندازه گیری کنیم[8]: نسبت فشردگی [^7] (چه میزان متن خلاصه شده،‌ کوتاه‌تر از متن اصلی است؟)
$$ CR =  \frac{lengthof Summary}{length of Full Text} $$
و نسبت نگهداری[^8](چه میزان از اطلاعات نگهداری شده است؟)
$$ RR =  \frac{information in Summary}{information Full Text} $$

ارزیابی‌ها برای ۱۰۰۰ خبر، نشان می‌دهد که میانگین نسبت فشردگی کارگزار خلاصه‌ساز خبر موجز، با روش پیشنهاد‌ داده‌شده برای حجم خلاصه، حدود ۶۷.۴۳ درصد است. نسبت نگهداری هم با معیارهایی نظیر دقت و فراخوانی مشخص می‌شود که در [بخش ۴.۱.۳](#sometext) محاسبه شده است.
معمولا ارزیابی‌های زیر برای ‌یک سیستم خلاصه‌ساز تعریف می‌شود:
## ۴.۱. ارزیابی ذاتی [^9]
تمرکز روش های ارزیابی ذاتی بر روی پیوستگی و اطلاع‌رسانی خلاصه ها است و تنها کیفیت خروجی بدون توجه به هدف نهایی مورد سنجش قرار می گیرد.
### ۴.۱.۱. پیوستگی خلاصه[^16]
گاهی اوقات، جملاتی که در خلاصه‌هایی که به روش مستخرج تولید می شوند دچار بی ارتباطی معنایی در دنباله جملات هستند. یکی سنجه‌ی پیوستگی خلاصه، درجه بندی جمله‌ها بر حسب میزان پیوستگی‌شان است. سپس باید درجه جملات خلاصه با امتیازات خلاصه های مرجع، با امتیازا جملات منبع، با با امتیازات سایز سیستم‌های خلاصه ساز، مقایسه شود.
### ۴.۱.۲ آموزندگی خلاصه[^17]
با مقایسه‌ی متن اصلی و متن خلاصه‌شده می‌توان اندازه گرفت که چه حجمی از اطلاعات متن اصلی، در خلاصه‌ی تولید شده توسط کارگزار حفظ شده است. البته این یک کمیت کیفی و اندازه گیری آن دشوار است. اما معیار‌‌هایی نظیر فراخوانی و دقت که در بخش ۴.۱.۳ توضیح داده شده‌اند تا حدی می‌توانند نمایانگر میزان حفظ اطلاعات به صورت کمی باشند.
<a name="sometext"></a>
### ۴.۱.۳ فراخوانی و دقت
از جمله معیارهای استاندارد در بازیابی اطلاعات، فراخوانی و دقت هستند: فراخوانی برابر با نسبت تعداد جملاتی که توسط سیستم درست تشخیص داده شده بر تعداد جملاتی که توسط سیستم معیار درست تشخیص داده شده اند،
$$ Precision Rate =  \frac{Number of Correctly Selected Sentences}{Total Number of Selected Sentences} $$
همچنین دقت برابر است با نسبت تعداد جملاتی که توسط سیستم درست تشخیص داده شده اند بر تعداد کل جملاتی که توسط سیستم برای خلاصه ایجاد شده اند،
$$ Recall Rate =  \frac{Number of Correctly Selected Sentences}{Total Number of Correct Sentences} $$
از ترکیب این دو معیار، معیاری تحت عنوان F-Measure ایجاد می‌شود. میزان وزن درنظر گرفته شده برای ترکیب دو معیار دقت و فراخوانی می‌تواند یکسان و یار غیر یکسان باشد در صورتی که یکسان باشند به آن $ F_{1} $ می‌گویند و مقدار آن از رابطه‌ی زیر بدست می‌آید.
$$ F = 2  \times  \frac{Precision.Recall}{Precision + Recall} $$
که این رابطه حالت خاصی از معیار  $ F_{ \beta } $  است(برای هر $ \beta $ حقیقی غیر منفی):
$$ F_{ \beta } = (1 + \beta^{2}) \times  \frac{Precision.Recall}{\beta^2 . Precision + Recall} $$
دو معیار  $F$ رایج دیگر، یکی $ F_{ 2 } $ است که به فراخوانی وزن بیش‌تری می‌دهد و دیگری $ F_{ 0.5 } $، که به دقت وزن بیش‌تری نسبت به فراخوانی می‌دهد. 
ارزیابی‌های انجام شده وقتی که نتایج مستخرج از آزمون‌دهنده‌های انسانی به عنوان معیار قرار گرفتند نشان می‌دهند که فعلا میانگین معیار دقت کارگزار موجز ۷۶ درصد و میانگین معیار فراخوانی آن ۶۱ درصد است. در نتیجه معیار $ F_{ 1 } $، برای این کارگزار در این فاز حدود  ۶۷.۶ درصد ارزیابی می‌شود.
## ۴.۲. ارزیابی بیرونی [^10]
کانون توجه در ارزیابی بیرونی، به روی کاربر است. در این روش میزان موثر بودن و قابلیت پذیرش خلاصه‌های تولید شده، با برخی از روش ها مثل ارزیابی رابطه‌ای یا خوانایی متن خلاصه، سنجیده می شود.
چندین سناریوی بازی به روش های سطحی برای ارزیابی خلاصه، پیشنهاد داده شده که در زیر تعدادی از آن ها را معرفی می کنیم:
### ۴.۲.۱. بازی شانون[^12]
بازی شانون،‌ نوعی از معیار شانون در نظریه اطلاعات(شانون ۱۹۸۴) است که تلاش می‌کند محتوای داده‌ها را با حدس‌زدنِ token بعدی(به عنوان مثال: کلمه یا جمله بعدی) به منظور رسیدن به متن اصلی، به شکل کمی ارزیابی کند. ایده‌ این است که شما، سه گروه از اطلاعات را برای بازسازی مهم‌ترین بخش متن در این زمان‌ها می‌پرسید: ۱.بدون دیدن هیچ متنی ۲.  پس از دیدنِ خلاصه‌ی تولید شده‌ توسط کارگزار ۳. بعد از دیدن متن اصلی خبر.
معیار نگهداری اطلاعات[^13] با اندازه‌گیری حدس‌های غلطی که برای بازسازی متن‌ِ اصلی زده شده است اندازه گیری می‌شود. ایراد این آزمون این است که بسیار به عملکرد آزمون‌دهنده در حدس زدن و دانش قبلی وی درباره موضوع بستگی دارد.
### ۴.۲.۲. بازی سوال [^11]
هدف بازی سوال ارزیابی میزان فهمِ خواننده، از متن خلاصه شده است. این ارزیابی دو گام دارد. ابتدا آزمون‌گر، متن مقاله را می‌خواند و قسمت اصلی متن را مشخص می‌کند و سوالاتی از حقایق مشخص از این قسمت‌ می‌سازد. در گام بعد، آزمون‌دهنده به سوالات،‌ در سه‌ زمان پاسخ می‌دهد: ۱.بدون دیدن هیچ متنی ۲.  پس از دیدنِ خلاصه‌ی تولید شده‌ توسط کارگزار ۳. بعد از دیدن متن اصلی خبر.
خلاصه‌ای بهتر است که آزمون‌دهنده‌ها بتوانند به سوالات بیشتری بعد از دیدن خلاصه‌ی صحیح پاسخ دهند. به عبارت بهتر خلاصه‌ای بهتر است که تفاوت پاسخ‌های آزمون‌دهنده، بین زمان‌های ۱ و ۲ زیاد و بین زمان‌های ۲ و ۳ کم باشد.
بازی سوال کارگزار موجز طراحی و انجام شد(فرم پرسش‌نامه را از  [این جا](http://moujez.ir/evaluation/1)  ببینید) چون این ارزیابی، یک ارزیابی کیفی است نمی‌توان نتایج را به صورت ارقام گزارش کرد. برای نمونه می‌توانید نتیجه‌ی چند پرسش‌نامه تکمیل شده توسط تعدادی آزمون‌دهنده را از [این جا](http://moujez.ir/result) مشاهده کنید. 
### ۴.۲.۳. بازی رده‌بندی [^14]
بازی رده‌بندی از آزمون‌دهنده‌(آزمون دهنده‌ می‌‌تواند یک کارگزار رده‌بندی متون یا یک انسان باشد ولی ترجیح با انسان است) می‌خواهد که خلاصه‌های تولید شده توسط کاربر و متون اصلی را به طور جداگانه رده‌بندی کند. عملکرد خلاصه‌سازی مطلوب است که رده‌های متون خلاصه‌‌شده و متن اصلی حداکثر شباهت را داشته‌ باشند.
با توجه به هزینه‌ی بالای رده بندی متون خبری و خروجی خلاصه‌ساز توسط انسان، از یک کارگزار رده‌بندی متون فارسی استفاده شد [^18]. برای حدود ۲۰۰ خبر، متن اصلی و خلاصه شده به صورت جداگانه رده‌بندی شدند. نتایج حاصل نشان دادند که دقیقا در ۷۵ درصد متون، متن اصلی خبر و متن خلاصه‌شده در یک رده قرار گرفتند.
### ۴.۲.۴. کلمات کلیدی انجمنی [^15]
کلمات کلیدی انجمنی یک روش کم‌هزینه اما سطحی نگر برای ارزیابی عملکرد کارگزار است که صحت خلاصه را با ارزیابی کلمات کلیدی انجمنی(می‌تواند خودکار یا دستی به دست آمده باشد) می‌سنجد. خلاصه‌سازی مطلوب است که کلمات کلیدی مشترک بیش‌تری بین متن اصلی و خلاصه‌شده وجود داشته باشد. مزیت این روش ساده‌‌بودن و عدم نیاز به تفسیر پیچیده است.
با توجه به این‌ که استخراج کلمات کلیدی توسط کاربر انسانی،‌ هزینه‌ی زیادی دارد ما از یک کارگزار استخراج کلمات کلیدی متن استفاده کرده‌ایم. در صورتی به یک کلمه کلیدی،کلمه‌ی کلیدی درست استخراج شده(Correctly Extracted) می‌گوییم که هم در خلاصه‌ و هم در متن اصلی کلمه‌ی‌کلیدی تشخیص داده شود و دو معیار فراخوانی و دقت را برای این روش به شکل زیر تعریف می‌کنیم:

$$ Precision Rate =  \frac{Number of Correctly Extracted Keywords}{Total Number of Extracted Keywords} $$

$$ Recall Rate =  \frac{Number of Correctly Extracted Keywords}{Total Number of Correct Keywords} $$

ارزیابی‌های کارگزار موجز، برای حدود ۱۰۰۰ خبر خلاصه‌شده نشان می‌دهند که میانگین معیار دقت ۹۲.۲ درصد و میانگین معیار فراخوانی ۹۴.۷ درصد است. 

# ۵. نتیجه‌گیری
مبحث خلاصه‌سازی یکی از مهم‌ترین مباحث حوزه متن‌کاوی[^20] و پردازش زبان‌های طبیعی [^19] است و خلاصه‌سازی یک ابزار عمده‌ی تجزیه و تحلیل سریع به شمار می‌رود. در سال‌های اخیر تاکید و تمرکز زیادی بر روی سیستم‌های خلاصه‌ساز صورت گرفته است و در همه‌ی سیستم‌ها تلاش بر این بوده که خلاصه حاصل شده به خلاصه‌های انسانی نزدیک شود. در این پژوهشنامه، ابتدا به تعریف خلاصه‌سازی و مراحل آن‌ پرداختیم سپس روش‌های مختلفی را برای خلاصه‌سازی بیان کردیم. در نهایت چندین روش برای خلاصه‌سازی یک متن پیاده سازی شد. همچنین کارهایی در مراحل پیش‌پردازش و پردازش انجام شدند که باعث بهبود نتایج تا سطح قابل قبولی شدند. به نظر می‌رسد برای تولید خلاصه مطلوب(در صورتی که زمان پردازش برای ما اهمیتی ندارد) بهتر است عمل خلاصه‌سازی را به چندین روش انجام دهیم و سپس خروجی‌ها را با هم مقایسه و ادغام کنیم. 
برای ارزیابی خلاصه‌سازهای زبان فارسی، مجموعه‌ای استاندارد از متون و خلاصه‌ی ایده آل آن‌ها، همانند آن‌چه در زبان انگلیسی وجود‌ دارد، موجود نیست که همین امر، ارزیابی و مقایسه عملکرد سیستم‌های خلاصه‌ساز فارسی را مشکل می‌کند و تنها می‌توان از روش‌های آماری برای ارزیابی آن‌ها استفاده کرد.

# ۶. مراجع
1. Afantenos, S., Karkaletsis, V., & Stamatopoulos, P. (2005). Summarization from medical documents: a survey. Intelligence in Medicine. Elsevier
2. Dalli, A., Xia, Y., & Wilks, Y. (2004). Fasil email summarisation system. Proceedings of the 20th International Conference. ACM
3. Bogdanovski, A. (2006). An Automatic Text Summarizer.
4. Hovy, E. H., Lin C.(1998), Automating Text Summarization in SUMMARIST, In I. Mani and M. Maybury (eds), Advances in Automated Text Summarization, MIT Press
5. Shamsfard, M., Akhavan, T., & Jourabchi, M. E. (2009). Parsumist: A Persian text summarizer. 2009 International Conference on Natural Language Processing and Knowledge Engineering, 1–7.
6. Moro, R. (2011) Personalized Text Summarization. Personalized Web - Science, Technologies and Engineering.
7. Smedt, K. De, & Liseth, A. (2004). How short is good? An evaluation of automatic summarization.
8. Hassel, M. (2004). Evaluation of automatic text summarization. Licentiate Thesis, Stockholm, Sweden.
9. Shamsfard, M. (2011). Challenges and open problems in Persian text processing. 5th Language & Technology Conference (LTC) 65–69.
10. Lee, S., & Kim, H.-J. (2008). News Keyword Extraction for Topic Tracking. 2008 Fourth International Conference on Networked Computing and Advanced Information Management
11. محسن مشکی، مرتضی آنالویی. خلاصه‌سازی چندسندی متون فارسی با استفاده از یک روش مبتی بر خوشه بندی. اولین کنفرانس مهندسی نرم‌افزار ایران. آموزشکده فنی و حرفه‌ای سما، رودهن
12. دستور خط زبان فارسی، مصوب فرهنگستان زبان و ادب فارسی (۱۳۸۹) . نشر آثار
13. Al-Hashemi, R. (2010). Text Summarization Extraction System (TSES) Using Extracted Keywords. Int. Arab J. E-Technol.164–168.
14. Chuang, W., & Yang, J. (2000). Extracting sentence segments for text summarization: a machine learning approach. Proceedings of the 23rd Annual International ACM, 152–159.
15. Barzilay, R., Elhadad, M. (1997). Using lexical chains for text summarization. Intelligent Scalable Text Summarization.
16. Das, D. (2007). A Survey on Automatic Text Summarization Single-Document Summarization, 1–31.
17. Gholamrezazadeh, S. (2009). A comprehensive survey on text summarization systems.

18. Elena Lloret, Teresa Rom, a-Ferri, Manuel Palomar. (2011). COMPENDIUM: A Text Summarization System for Generating Abstracts of Research Papers. Lecture notes in computer science. Springer

19. Jing, H. (2000). Sentence reduction for automatic text summarization. Proceedings of the Sixth Conference on Applied Natural…, 310–315.
20. Li, Y., & Cheng, K. (2011). Single document Summarization based on Clustering Coefficient and Transitivity Analysis.
21. Mani, I. (2001). Summarization evaluation: An overview.
22. Nenkova, A. (2011). Automatic Summarization. In Foundations and Trends® in Information Retrieval (Vol. 5, pp. 103–233).
23. Neto, J., Freitas, A., & Kaestner, C. (2002). Automatic text summarization using a machine learning approach. Advances in Artificial Intelligence, (i).
24. Sjobergh, J., & Araki, K. (2006). Extraction based summarization using a shortest path algorithm. Proceedings of 12th Annual Language Processing ….
25. Steinberger, J. (2004). Using Latent Semantic Analysis in Text Summarization.
26. Thakkar, K., & Shrawankar, U. (2011). Test Model for Text Categorization and Text Summarization. International Journal on …,1539–1545.
27. Tofighy, M., Kashefi, O., & Zamanifar, A. (2011). Persian Text Summarization Using Fractal Theory. Springer, 651–662.
28. Jing, H., Barzilay, R., McKeown, K., & Elhadad, M. (1998). Summarization evaluation methods: Experiments and analysis. … on Intelligent Summarization, 51–59.
29. Wong, L. (n.d.). ANSES: Automatic News Summarization and Extraction System.
30. ت. اخوان، م. شمس فرد، م. عرفانی(۱۳۸۷). PARSUMIST: خلاصه ساز تک سندی و چند سندی متون فارسی. چهاردهمین کنفرانس ملی انجمن کامپیوتر ایران

## توضیحات تکمیلی و ضمایم
### لیست کلمات ایست فارسی

[این لینک](http://moujez.ir/static/files/persian) یک لیست ۵۰۰ تایی از کلمات ایست فارسی است. در این لیست تعدادی واژه که در یک خبر نباید حذف شوند نیز وجود دارد. شاید بعضی از واژه‌ها هم در متون خبری وجود داشته باشند که در خبر کلمه ایست به شمار بیایند و یک متن عمومی این‌طور نباشد. این لیست از کلمات ایست، بایستی متناسب با متون خبری تغییر کند.

### پیکره‌ی آزاد متون خلاصه‌ی زبان فارسی
یکی از دوستان در ارزیابی‌شان پیشنهاد داده بودند که یک [پیکره‌ی آزاد از متون و خلاصه‌ی آن‌ها برای زبان فارسی](https://github.com/kharazi/Corpusum) ایجاد کنیم. من برای این‌ پروژه، حدود ۵۰ سند را به شکل دستی خلاصه‌ کردم و از آن‌ها برای ارزیابی استفاده می‌کردم.  پس از مرتب کردن آن‌ها در فرم استاندارد یک پیکره‌ به زودی آن‌ها را در آدرس مخزنی که لینک شده است قرار خواهم داد. همچنین یک ساز و کار که بشود خیلی راحت، خلاصه‌های انسانی را جمع آوری کرد را در ویکی همین پروژه مطرح می‌کنم تا ان‌شاالله کد آن را بنویسیم. لطفا اگر تمایل دارید که در این کار همکاری کنید در [این issue](https://github.com/kharazi/Corpusum/issues/1) نظرتان را مطرح کنید. 

[^1]: Agent
[^2]: Precision
[^3]: Recall
[^4]: Extract
[^5]: Abstract
[^6]: Stop Words
[^7]: Compression Ratio
[^8]: Retension Ratio
[^9]: Intrinsic Evaluation
[^10]: Extrinsic Evaluation
[^11]: Question Game
[^12]:Shannon Game
[^13]:Information Retention
[^14]: Classification Game
[^15]: Keyword Association
[^16]: Summary Coherence
[^17]: Summary Informativeness (در صورتی که واژه بهتری برای ترجمه این عبارت به نظرتان می‌رسد لطفا پیشنهاد دهید)
[^18]: از کد [پروژه‌ی آقای محمودی](http://www.boute.ir/ai/document-classification) برای رده‌بندی استفاده شد. با تشکر از ایشان!
[^19]: Natural Language Processing
[^20]: Text Mining
[^21]: Machine Learning
